{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import seaborn as sbn\n",
    "import json, re, time, unicodedata, unidecode, codecs, random, math, warnings\n",
    "from pprint import pprint\n",
    "from lxml import etree\n",
    "from pattern.nl import parse, split, parsetree\n",
    "from collections import defaultdict, Counter\n",
    "from datetime import date, datetime, timedelta\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from pattern.nl import sentiment\n",
    "import pandas as pd\n",
    "from scipy.stats.mstats import normaltest\n",
    "from tqdm import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# files\n",
    "#MWE\n",
    "#topics = json.load(open('D:\\\\4. Data\\\\Amazones_Forum_Export_JSON\\\\MWE_topic.json'))\n",
    "#posts = json.load(open('D:\\\\4. Data\\\\Amazones_Forum_Export_JSON\\\\MWE.json'))\n",
    "#regular\n",
    "forums = json.load(open('D:\\\\4. Data\\\\Amazones_Forum_Export_JSON\\\\2017-12-07T13-35-45 _amazones_forums_export.json'))\n",
    "topics = json.load(open('D:\\\\4. Data\\\\Amazones_Forum_Export_JSON\\\\2017-12-07T13-36-51_amazones_forum_topics_export.json'))\n",
    "posts = json.load(open('D:\\\\4. Data\\\\Amazones_Forum_Export_JSON\\\\2017-12-07T13-39-20_amazones_forum_posts_export.json'))\n",
    "users = json.load(open('D:\\\\4. Data\\\\Amazones_Forum_Export_JSON\\\\2017-12-07T13-39-20_amazones_users_export.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove non-ascii characters from file (otherwise they will become part of the tokens)\n",
    "def remove_non_ascii(text):\n",
    "    return unidecode.unidecode(text)\n",
    "    #return ''.join([i if ord(i) < 128 else ' ' for i in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cleanup(text):\n",
    "    #remove all links, images, quotes, and emailaddresses\n",
    "    text=re.sub('<a.*?>(.*?)</a>','',text) #remove links\n",
    "    text=re.sub('(http:|www)\\S*','',text) #remove links without markup\n",
    "    text=re.sub('\\[\\\\\\/url\\]','',text)\n",
    "    text=re.sub('<img.*?/>', '',text) #remove images\n",
    "    text=re.sub('<div class=\"bb-quote\">((\\s|\\S)*?)</div>','',text) #remove quotes\n",
    "    text=re.sub('<script.*?>([\\S\\s]*?)</script>','',text) #remove emailaddresses\n",
    "\n",
    "    #replace all emoticon-icons\n",
    "    text=re.sub('<img.*?title=\"(.*?)\".*?/>', '(EMO:\\\\1)',text) #replace emoticons by textual indicators \n",
    "\n",
    "    # replace (most) sideways latin emoticons\n",
    "    text=re.sub('[^>]:-?(\\)|\\])','(EMO:smiley)',text)\n",
    "    text=re.sub(u'☺️','(EMO:smiley)',text)\n",
    "    text=re.sub('[^>]:-?(\\(|\\[)','(EMO:sad)',text)\n",
    "    text=re.sub(';-?(\\)|\\])','(EMO:wink)',text)\n",
    "    text=re.sub(r'(:|;|x|X)-?(D)+\\b','(EMO:laugh)',text)\n",
    "    text=re.sub(':-?(/|\\\\\\|\\|)','(EMO:frown)',text)\n",
    "    text=re.sub(r'(:|;)-?(p|P)+\\b','(EMO:cheeky)',text)\n",
    "    text=re.sub('(:|;)(\\'|\\\")-?(\\(|\\[)','(EMO:cry)',text)\n",
    "    text=re.sub('\\<3+','(EMO:heart)',text)\n",
    "    text=re.sub(u'❤️','(EMO:heart)',text)\n",
    "    text=re.sub('((\\>:-?(\\(|\\]))|(\\>?:-?@))','(EMO:angry)',text)\n",
    "    text=re.sub('\\>:-?(\\)|\\])','(EMO:evil)',text)\n",
    "    text=re.sub(r'(:|;)-?(O|o|0)+\\b','(EMO:shock)',text)\n",
    "    text=re.sub('(:|;)-?(K|k|x|X)','(EMO:kiss)',text)\n",
    "    # :s\n",
    "    # :x is eigenlijk geen kus, geloof ik...\n",
    "\n",
    "\n",
    "    #other important adjustments:\n",
    "    text=re.sub('m\\'?n\\s','mijn ',text) # replacing m'n and mn with mijn, so it gets parsed correctly.\n",
    "    text=re.sub('z\\'?n\\s','zijn ',text) #replacing z'n and zn with zijn\n",
    "    text=re.sub('d\\'?r\\s','haar ',text) #replacing d'r and dr with zijn (only if followed by space, so dr. stays dr.)\n",
    "\n",
    "    # replace all emoticons (and other things) written between double colons\n",
    "    text=re.sub(':([a-zA-Z]+):','(EMO:\\\\1)',text)\n",
    "\n",
    "    # remove remaining markup\n",
    "    text=re.sub('</?(ol|style|b|p|em|u|i|strong|br|span|div|blockquote|li)(.*?)/?>','',text)\n",
    "    text=re.sub('(\\[|\\]|\\{|\\})', '',text)\n",
    "\n",
    "    # separate text from punctuation (may cause double/triple spaces - does not matter at this point)\n",
    "    text = re.sub('(\\.{2,}|/|\\)|,|!|\\?)','\\\\1 ',text) # space behind\n",
    "    text=re.sub('(/|\\()',' \\\\1',text) # space in front\n",
    "    text=re.sub('(\\w{2,})(\\.|,)','\\\\1 \\\\2 ',text) #space 'between'\n",
    "\n",
    "    return(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make two dictionaries: user's post T imes, and user's P ost texts.\n",
    "def make_P_T_and_D(topics,posts,count=2500):\n",
    "    P = defaultdict(list)\n",
    "    T = defaultdict(list)\n",
    "    D = []\n",
    "\n",
    "    for t in reversed(topics):    \n",
    "        P[t['Author uid']].append((remove_non_ascii(cleanup(t[\"Body\"])),1))\n",
    "        T[t['Author uid']].append(t['Post date'])\n",
    "        D.append(datetime.strptime(t['Post date'], '%d/%m/%Y - %H:%M'))\n",
    "\n",
    "        count-=1\n",
    "        if count-1<=0:\n",
    "            break\n",
    "        for p in reversed(posts):\n",
    "            if p['Forum Topic ID'] == t['Nid']:\n",
    "                P[p['Auteur-uid']].append((remove_non_ascii(cleanup(p[\"Body\"])),0))\n",
    "                T[p['Auteur-uid']].append(p['Datum van inzending'])\n",
    "                D.append(datetime.strptime(p['Datum van inzending'], '%d/%m/%Y - %H:%M'))\n",
    "\n",
    "                count-=1\n",
    "                if count-1<=0:\n",
    "                    break\n",
    "    return (P,T,D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_binlist(D,timetick=1): #timetick in days\n",
    "    lower = min(D)\n",
    "    upper = max(D)\n",
    "\n",
    "    if lower.time()>=datetime.strptime('4:00','%H:%M').time():\n",
    "        lower = lower.replace(hour = 4, minute = 0)\n",
    "    else:\n",
    "        lower = (lower+timedelta(days = -1)).replace(hour=4,minute=0)\n",
    "\n",
    "    if upper.time()<datetime.strptime('12:00','%H:%M').time():\n",
    "        upper = upper.replace(hour = 4, minute = 0)\n",
    "    else:\n",
    "        upper = (upper+timedelta(days=1)).replace(hour=4,minute=0)\n",
    "\n",
    "        return([lower + timedelta(days=x) for x in range(0, (upper-lower).days, timetick)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def determine_questionmarks(body):\n",
    "    Q = 0\n",
    "    for sentence in sent_tokenize(body):\n",
    "        if re.search('\\?+', sentence):\n",
    "            Q+=1\n",
    "    if len(sent_tokenize(body))!=0:\n",
    "        return float(Q)/float(len(sent_tokenize(body)))\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# expects a string\n",
    "# returns an int, representing the average sentiment score per sentence in the string, calculated by pattern\n",
    "def determine_sentiment(body):\n",
    "    S = []\n",
    "    for sentence in sent_tokenize(body):\n",
    "        S.append(sentiment(sentence)[0])\n",
    "    return np.mean(S)\n",
    "\n",
    "# expects a string\n",
    "# returns an int, representing the average objectivity score per sentence in the string, calculated by pattern\n",
    "def determine_objectivity(body):\n",
    "    O = []\n",
    "    for sentence in sent_tokenize(body):\n",
    "        O.append(sentiment(sentence)[1])\n",
    "    return np.mean(O)\n",
    "\n",
    "# expects a string\n",
    "# returns an int, representing the total nr of sentences the string is built of\n",
    "def determine_length(body):\n",
    "    # in sentences:\n",
    "    return(len(sent_tokenize(body)))\n",
    "\n",
    "# expects a string\n",
    "# returns an int, representing the average nr of words in sentences that occur in the string\n",
    "def determine_sent_length(body):\n",
    "    # in words:\n",
    "    L = []\n",
    "    for sentence in sent_tokenize(body):\n",
    "        L.append(len(word_tokenize(sentence)))\n",
    "    return np.mean(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compare_variables(pp,user,nr_of_posts,mean_quest,mean_object,mean_sents,mean_length,mean_sents_length,nr_of_starts,nr_of_responses):\n",
    "    fig = plt.figure(1)\n",
    "    ax = plt.subplot(111)\n",
    "\n",
    "    posts, = ax.plot(nr_of_posts.values(),'b.', label = 'nr of posts', alpha = 1) #blue\n",
    "    senlength, = ax.plot(mean_sents_length.values(),'k.', label = 'mean sentence length (words)',alpha = 0) #yellow\n",
    "    postlength, = ax.plot(mean_length.values(),'c.', label = 'mean post length (sentences)',alpha = 0) #cyan\n",
    "    starts, = ax.plot(nr_of_starts.values(),'g.', label = 'start posts', alpha = 0) #black\n",
    "    #responses, = ax.plot(nr_of_responses.values(),'y.', label = 'response posts', alpha = 0.5)\n",
    "    \n",
    "    first_legend = plt.legend(handles=[posts,senlength,postlength,starts], title = \"left axis\", loc='upper left', bbox_to_anchor=(0, -0.1),ncol=1)\n",
    "    axx = plt.gca().add_artist(first_legend)\n",
    "    \n",
    "    ax1 = ax.twinx()\n",
    "    qmarks, = ax1.plot(mean_quest.values(),'y.', label = 'question ratio',alpha = 0) #green\n",
    "    ovalues, = ax1.plot(mean_object.values(),'r.', label = 'subjectivity',alpha = 0) #red\n",
    "    svalues, = ax1.plot(mean_sent.values(),'m.', label = 'sentiment',alpha = 0) #magenta\n",
    "    \n",
    "    \n",
    "    second_legend = plt.legend(handles=[qmarks,ovalues,svalues], title = \"right axis\",loc='upper right', bbox_to_anchor=(1, -0.1),ncol=1)\n",
    "\n",
    "    ax.set_ylim(0,10)\n",
    "    ax1.set_ylim(-1,1)\n",
    "    \n",
    "    box = ax.get_position()\n",
    "    ax.set_position([box.x0, box.y0 + box.height, box.width, box.height * 0.7])\n",
    "    box = ax1.get_position()\n",
    "    ax1.set_position([box.x0, box.y0 + box.height, box.width, box.height * 0.7])\n",
    "    \n",
    "    plt.title(user)\n",
    "    plt.show()\n",
    "    pp.savefig(fig, dpi = 300, transparent = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compare_two(user,x,y):\n",
    "    x = x.values()\n",
    "    y = y.values()\n",
    "    \n",
    "    plt.plot(x,y, 'bo', alpha = 0.1)\n",
    "    plt.xlabel('questions per post')\n",
    "    plt.ylabel('nr of responses')\n",
    "    plt.xlim(0,10)\n",
    "    plt.ylim(0,10)\n",
    "    plt.title(\"correlation plot\")\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# determine which variables are non-normal, and make a mask for correlations that are measured nonparametrically\n",
    "def mask_nonnormal(df,mask):\n",
    "    for column in df:\n",
    "        index = df.columns.get_loc(column)\n",
    "        z,p = normaltest(df[column].tolist())\n",
    "        # als de data in de kolom significant niet-normaal verdeeld is, activeer dan het maskeer voor de relevante rij en kolom\n",
    "        if p<0.05:\n",
    "            mask[index]=True #rijen blokkeren\n",
    "            mask[0::1,index]=True #kolommen blokkeren\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def visualise(df, method):\n",
    "    global averagedict, normaldict, nonnormaldict, countnonnormal\n",
    "    rho = df.corr(method = m)\n",
    "    mask = np.zeros_like(rho, dtype=np.bool)\n",
    "    \n",
    "    if method == 'pearson' or method == 'spearman':\n",
    "        mask = mask_nonnormal(df,mask)\n",
    "        cmap = sbn.diverging_palette(120, 260, n=21, s=80)\n",
    "        cbar_kws= dict(use_gridspec=False,location=\"left\",label= \"Pearson's Rho\")\n",
    "    else:\n",
    "        mask = ~mask_nonnormal(df,mask)\n",
    "        cmap = sbn.diverging_palette(10, 30, n=21, s=99, l=65)\n",
    "        cbar_kws = dict(use_gridspec=False,location=\"right\",label= \"Kendall's Tau\")\n",
    "\n",
    "    #mask the upper half of the figure\n",
    "    mask[np.triu_indices_from(mask)] = True\n",
    "    \n",
    "    # calculate averages        \n",
    "    for i,row in enumerate(mask):\n",
    "        for j,column in enumerate(row):\n",
    "            if column == False: # all unmasked positions\n",
    "                averagedict[i,j].append(rho.iloc[i][j])\n",
    "                if method == 'pearson' or method == 'spearman':\n",
    "                    normaldict[i,j].append(rho.iloc[i][j])\n",
    "                else:\n",
    "                    nonnormaldict[i,j].append(rho.iloc[i][j])\n",
    "                    countnonnormal[i,j].append(1)\n",
    "    \n",
    "    # make heatmap\n",
    "    ax = sbn.heatmap(rho, mask=mask, cbar_kws = cbar_kws, cmap=cmap, vmin = -1, vmax = 1, annot = True, fmt='1.2f')\n",
    "    plt.title('results of (non-)parametric correlation tests')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_correlations(dictionaries,countnonnormal,rho):\n",
    "    for d in dictionaries:\n",
    "        frame = pd.DataFrame().reindex_like(rho)\n",
    "        for (i,j) in d:\n",
    "            frame.iloc[i][j]=np.nanmean(d[(i,j)])\n",
    "        print frame\n",
    "\n",
    "    frame = pd.DataFrame().reindex_like(rho)\n",
    "    for (i,j) in countnonnormal:\n",
    "        frame.iloc[i][j]=np.nansum(countnonnormal[(i,j)])\n",
    "    print frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PTD = make_P_T_and_D(topics,posts) \n",
    "P = PTD[0]\n",
    "T = PTD[1]\n",
    "D = PTD[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                          | 0/307 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User:  1783 - Active bins:  39\n",
      "last:  25/10/2014 - 09:36  - first: 14/06/2007 - 16:43  = active time: 2689 days, 16:53:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|██▏                                                                               | 8/307 [00:03<01:58,  2.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User:  1370 - Active bins:  99\n",
      "last:  26/08/2012 - 12:50  - first: 09/01/2006 - 22:04  = active time: 2420 days, 14:46:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|██████▎                                                                          | 24/307 [00:10<02:06,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User:  934 - Active bins:  32\n",
      "last:  14/08/2006 - 14:11  - first: 20/09/2004 - 22:24  = active time: 692 days, 15:47:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█████████▏                                                                       | 35/307 [00:13<01:44,  2.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User:  1312 - Active bins:  31\n",
      "last:  23/04/2009 - 19:00  - first: 05/07/2006 - 19:41  = active time: 1022 days, 23:19:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|██████████▌                                                                      | 40/307 [00:16<01:47,  2.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User:  1015 - Active bins:  44\n",
      "last:  27/08/2007 - 20:16  - first: 13/06/2006 - 21:45  = active time: 439 days, 22:31:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|████████████▉                                                                    | 49/307 [00:19<01:40,  2.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User:  1825 - Active bins:  47\n",
      "last:  22/03/2012 - 09:05  - first: 13/08/2007 - 15:21  = active time: 1682 days, 17:44:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|███████████████▌                                                                 | 59/307 [00:22<01:36,  2.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User:  1062 - Active bins:  102\n",
      "last:  16/08/2011 - 09:24  - first: 19/05/2005 - 14:04  = active time: 2279 days, 19:20:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▎                                                                | 62/307 [00:30<02:02,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User:  1405 - Active bins:  41\n",
      "last:  18/04/2007 - 11:28  - first: 10/03/2006 - 20:54  = active time: 403 days, 14:34:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██████████████████▍                                                              | 70/307 [00:34<01:55,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User:  902 - Active bins:  119\n",
      "last:  21/06/2014 - 16:58  - first: 02/09/2004 - 07:34  = active time: 3579 days, 9:24:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|██████████████████████████████████▍                                             | 132/307 [00:43<00:57,  3.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User:  901 - Active bins:  67\n",
      "last:  02/12/2006 - 11:12  - first: 05/09/2004 - 20:35  = active time: 817 days, 14:37:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|██████████████████████████████████▉                                             | 134/307 [00:48<01:03,  2.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User:  1000 - Active bins:  83\n",
      "last:  25/04/2012 - 15:51  - first: 04/02/2005 - 10:36  = active time: 2637 days, 5:15:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|███████████████████████████████████████▊                                        | 153/307 [00:55<00:55,  2.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User:  1503 - Active bins:  74\n",
      "last:  28/09/2007 - 09:08  - first: 13/06/2006 - 21:38  = active time: 471 days, 11:30:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|███████████████████████████████████████████████▉                                | 184/307 [01:01<00:40,  3.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User:  1033 - Active bins:  52\n",
      "last:  16/11/2009 - 16:37  - first: 10/02/2005 - 21:30  = active time: 1739 days, 19:07:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 61%|████████████████████████████████████████████████▉                               | 188/307 [01:05<00:41,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User:  905 - Active bins:  143\n",
      "last:  17/11/2009 - 10:48  - first: 01/09/2004 - 11:26  = active time: 1902 days, 23:22:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|████████████████████████████████████████████████████████                        | 215/307 [01:15<00:32,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User:  1 - Active bins:  81\n",
      "last:  12/02/2014 - 23:32  - first: 03/09/2004 - 00:33  = active time: 3449 days, 22:59:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|███████████████████████████████████████████████████████████████████▍            | 259/307 [01:21<00:15,  3.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User:  6131 - Active bins:  35\n",
      "last:  17/12/2007 - 10:26  - first: 01/02/2005 - 13:40  = active time: 1048 days, 20:46:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 307/307 [01:23<00:00,  3.67it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAHppJREFUeJzt3XmYXVWZ7/HvL1WpqlQlZIZAyCRC\noiCTpSJBpUUbWhFaW0Uu4oAtehVFW8GhuU73dkNfvT5ip9unI04gHe1GuNDKbbQRRByACoNMIjxA\nZYCQykSmGpKq9/6xdu06VGo4lcqpXcPv8zznOWevs/fZ7zmQ89Zaa5/1KiIwMzMDmFR0AGZmNno4\nKZiZWc5JwczMck4KZmaWc1IwM7Ock4KZmeWcFMwASbdL+uv9PHahpJ2Sqg50XIOc932S7hzJc9r4\n56RgNkSSnpb0hu7tiFgTEVMjorPIuAYynKRnE4uTgo0rkqrLaTOzvjkp2KghaYGk6yW1SNosaUXW\nPknSZZKaJW2UdLWk6dlziyWFpA9IWgP8sq+2bN+TJP1W0jZJD0g6tZ84jpD0yyyGTZKulTQje+4a\nYCHwH9mQ0aUl56vO9jlM0k2Stkh6QtIHS177S5L+LXsPOyQ9LKlxgM8kJH1c0pNZLF+V1Oe/W0kn\nS7pH0vPZ/clZ+98BrwFWZDGvGOJ/GptAnBRsVMjG438KNAOLgfnAj7Kn35fd/gx4ETAV6P3F9jrg\nJcDpfbVJmg/8DPhfwCzg08BPJM3tKxzgcuCw7PgFwJcAIuJ8YA3wlmzI6H/3cfwqYF12/NuBv5d0\nWsnzZ2XvbQZwUx/vpbe3Ao3AicDZwAX7BCzNyt7fN4HZwNeBn0maHRF/C/wauCiL+aJBzmcTmJOC\njRavJH2JXhIRuyKiLSK6J1HPA74eEU9GxE7gc8C7eg0LfSk7rrWftncDN0fEzRHRFRG/AJqAN/UO\nJCKeiIhfRER7RLSQvmBfV86bkLQAOAX4TPYe7geuAs4v2e3OLI5O4BrguEFe9h8iYktErAG+AZzb\nxz5vBh6PiGsiYm9ErAL+CLylnLjNunms1UaLBUBzROzt47nDSD2Ibs2k/3cPKWlb28dxpW2LgHdI\nKv2SnAzc1vsgSQeT/uJ+DTCN9MfT1jLeQ3esWyJiR694S4eINpQ83g3USaru5733fh/N2Tn6Om9z\nr7ZmUo/LrGzuKdhosRZY2M+k8DOkL/VuC4G9wHMlbX0t91vatha4JiJmlNwaIuKKPo67PDv22Ig4\niNTL0CDnKo11lqRpveJdP8Axg1nQ67We6ee8i3q1lZ7XyyFbWZwUbLS4G3gWuEJSg6Q6Scuz51YB\nn5S0RNJU4O+BHw/wl3Vffgi8RdLpkqqy1z9V0uF97DsN2Alsy+YiLun1/HOkuY19RMRa4LfA5dk5\njgU+AFw7hFh7u0TSzGxo6mLgx33sczNwlKT/Jqla0jnAS0nzNAPGbFbKScFGhWx8/S3Ai0kTueuA\nc7Knv0sae78DeApoAz42xNdfS5qk/TzQQuo5XELf/wa+TJrUfZ40eXt9r+cvBy7LrmL6dB/Hn0ua\nLH8GuAH4YjaHsb9uBFYD92fxfKf3DhGxGTgT+BSwGbgUODMiNmW7XAm8XdJWSd8cRiw2zslFdsxG\nL0kBHBkRTxQdi00M7imYmVmuYklB0nezHxo9VNI2S9IvJD2e3c+s1PnNzGzoKtlT+D5wRq+2zwK3\nRsSRwK3Ztpn1IyLkoSMbSRWdU5C0GPhpRByTbT8GnBoRz0o6FLg9IpZWLAAzMxuSkf7x2iER8SxA\nlhgO7m9HSRcCFwI0NDS8fNmyZSMUopnZ+LB69epNEdHXUi79GrW/aI6IlcBKgMbGxmhqaio4IjOz\nsUVS71+5D2qkrz56Lhs2IrvfOMLnNzOzAYx0UrgJeG/2+L2kH+WYmdkoUclLUlcBvwOWSlon6QPA\nFcAbJT0OvDHbNjOzUaJicwoR0dfyvgCn9dNuZmYF8y+azcws56RgZmY5JwUzM8s5KZiZWc5JwczM\nck4KZmaWc1IwM7Ock4KZmeWcFMzMLOekYGZmOScFMzPLOSmYmVnOScHMzHJOCmZmlnNSMDOznJOC\nmZnlnBTMzCznpGBmZjknBTMzyzkpmJlZzknBzMxyTgpmZpZzUjAzs5yTgpmZ5ZwUzMws56RgZmY5\nJwUzM8s5KZiZWc5JwczMck4KZmaWc1IwM7Ock4KZmeWcFMzMLOekYGZmOScFMzPLFZIUJH1S0sOS\nHpK0SlJdEXGYmdkLjXhSkDQf+DjQGBHHAFXAu0Y6DjMz21dRw0fVwBRJ1UA98ExBcZiZWYkRTwoR\nsR74GrAGeBZ4PiJ+3ns/SRdKapLU1NLSMtJhmplNSEUMH80EzgaWAIcBDZLe3Xu/iFgZEY0R0Th3\n7tyRDtPMbEIqYvjoDcBTEdESEXuA64GTC4jDzMx6KSIprAFOklQvScBpwKMFxGFmZr0UMadwF3Ad\ncC/wYBbDypGOw8zM9lVdxEkj4ovAF4s4t5mZ9c+/aDYzs5yTgpmZ5ZwUzMws56RgZmY5JwUzM8s5\nKZiZWc5JwczMck4KZmaWc1IwM7Ock4KZmeWcFMzMLOekYGZmOScFMzPLFbJK6lB1dMCf/gR1dTB1\nKuzcCW1taXvuXJgypegIzczGhzHRU4iAhgbYtQt+//uUFBoaoLMTmpuhtbXoCM3MxocxkRQmTQIJ\nduxIPYVdu9J2bW26tbQUHaGZ2fgwJpJCt/Z2qK9PQ0fdampeuG1mZvtvTCWF2lrYvTvNJXTr6Hjh\ntpmZ7b8xkRS6utK8wrRpPfMJEann0N6eJpvNzGz4xkRSkNI8QkMDnHRSz7xCVRUsWuSrj8zMDpQx\ncUlqTQ0cdVTP9qxZxcViZjaejYmegpmZjYxBk4Kk5ZIassfvlvR1SYsqH5qZmY20cnoK3wJ2SzoO\nuBRoBq6uaFRmZlaIcpLC3ogI4Gzgyoi4EphW2bDMzKwI5Uw075D0OeB84DWSqoDJlQ3LzMyKUE5P\n4RygHbggIjYA84GvVjQqMzMrxKBJIUsEPwFqs6ZNwA2VDMrMzIpRztVHHwSuA/4la5oP/N9KBmVm\nZsUoZ/joo8ByYDtARDwOHFzJoMzMrBjlJIX2iOjo3pBUDUTlQjIzs6KUkxR+JenzwBRJbwT+HfiP\nyoZlZmZFKCcpfBZoAR4EPgTcDFxWyaDMzKwYg/5OISK6gG8D35Y0Czg8+zGbmZmNM4MmBUm3A2dl\n+94PtEj6VUT8zf6eVNIM4CrgGNL8xAUR8buBjmltTWU3t23rWTa7szMtpz1jRqqp4CW0zcyGp5xf\nNE+PiO2S/hr4XkR8UdIfhnneK4H/jIi3S6oB6gfauasLmptTYZ0tW2DPHnj2WZg3L1Veq65OFdlc\nW8HMbHjKmVOolnQo8E7gp8M9oaSDgNcC3wGIiI6I2DbQMXv3plKcO3ak0psdHanQTnf7rl3pvqVl\nuNGZmU1s5SSFrwC3AE9ExD2SXgQ8Poxzvog0cf09SfdJuqp7ae5Ski6U1CSpafPmLdTUpNKbkyen\npDBlSs92W1sqxNPWNoyozMysrGUu/j0ijo2Ij2TbT0bEXw3jnNXAicC3IuIEYBfpCqfe510ZEY0R\n0Th79iw6OlJvYM+elABaW3u2u3sPdXXDiMrMzMqaaJ4LfBBYXLp/RFywn+dcB6yLiLuy7evoIym8\nIMjq1CuYNg2eey4lhc2b0xBSe3uaZG5vT3MKZma2/8qZaL4R+DXwX0DncE8YERskrZW0NCIeA04D\nHhnomEmT0hd+S0uqz7xrFyxb1nP10dSpvvrIzOxAKCcp1EfEZw7weT8GXJtdefQk8P7BDpgyBRYu\nTDczM6uMcpLCTyW9KSJuPlAnjYj7gcYD9XpmZnZglHP10cWkxNAmaUd2217pwMzMbOSVs8yF6zGb\nmU0Q5QwfIeks0g/OAG6PiGH/iM3MzEafciqvXUEaQnoku12ctZmZ2ThTTk/hTcDx2WqpSPoBcB+D\n/LbAzMzGnnImmgFmlDyeXolAzMyseOX0FC4H7pN0GyDS3MLnKhqVmZkVopyrj1ZlNRVekTV9JiI2\nVDQqMzMrRFlXHwGvBk4hFcSpAm6oWERmZlaYcq4++mfgw6QazQ8BH5L0T5UOzMzMRl45PYXXAcd0\n12XOrj56sKJRmZlZIcq5+ugxoHQZugXAcMtxmpnZKFROT2E28Kiku7PtVwC/k3QTQEScVangzMxs\nZJWTFL5Q8SgG0dYGt9wCGzemCms1NXDwwbBkCSxY0FNHobU11Vxoa0tV2FxjwcxsaMpJCk1Aa0R0\nSToKWAb8v4jYU9nQerS3w4YN6Qt/yxaYPRsiYO9e2L0bli5N+zU3pxKdDQ0peTQ3p+I8TgxmZuUp\nZ07hDqBO0nzgVlJBnO9XMqjeIlKVtUmTYObM1LZnT7rt2pWSRUtLSgi1tSD1PG5pGclIzczGtnKS\ngiJiN/A24B8j4q3A0ZUNa19dXelWV5eSRETa7uxMw0VtbWlYqVRNTWo3M7PylJUUJL0aOA/4WdZW\nVbmQ+jZpUrq1taWegJS2q6pSoqirS0NGpTo6UruZmZWnnKTwCdJaRzdExMOSXgTcVtmwXkhKX/5d\nXbB1a2qbPDndGhrShPLcuWnuob099SK6H8+dO5KRmpmNbeWsffQr4FeSGrLtJ4GPVzqwUrW1MG9e\nz5xCf1cfLVqU5hB27Uo9BE8ym5kNzaBJIRs6+g4wFVgo6TjgQxHxkUoH162uDk4/ffD9pkyBhQsH\n38/MzPpWzvDRN4DTgc0AEfEAPaU5zcxsHCmryE5ErO3V1FmBWMzMrGDl/HhtraSTgZBUQ5pPeLSy\nYZmZWRHK6Sl8GPgoMB9YBxyfbZuZ2TgzYE9BUhVwfkScN0LxmJlZgQbsKUREJ3D2CMViZmYFK2dO\n4TeSVgA/BnZ1N0bEvRWLyszMClFOUjg5u/9KSVsArz/w4ZiZWZHK+UXzn41EIGZmVryyfqdgZmYT\ng5OCmZnl+k0Kkt6R3S8ZuXDMzKxIA/UUPpfd/2QkAjEzs+INNNG8WdJtwBJJN/V+MiLOqlxYZmZW\nhIGSwpuBE4FrgP9zoE+c/Vq6CVgfEWcOtO/TT8O558Ls2XDooam2QndRnY0bYe9eqK5OtRWWLUv3\nkGortLWlpbfnznVtBTOzwfSbFCKiA/i9pJMjokXStNQcOw/QuS8mLax30GA7RqTE8PjjcPzx6b6m\nJn3R79kDO3bAEUfAE0+kBLFlS0oE06enymwdHdDc7KI7ZmaDKefqo0Mk3Qc8BDwiabWkY4ZzUkmH\nk3oiV5Wzf2cnzJmTegoPP5y+6HfvhjVr0pf8zJkpMUybBps3w/r1qfpabW0q5Vlbm24tLcOJ2sxs\n/CsnKawE/iYiFkXEQuBTWdtwfAO4FOjqbwdJF0pqktTU3t5ObW1KBjt3pnrNnZ3Q2prqNk+ZkoaJ\npkxJQ0ptben5UjU1qd3MzPpXTlJoiIjbujci4nagYX9PKOlMYGNErB5ov4hYGRGNEdFYW1tLe3v6\n63/q1PSFX1WVksCkSSk51NWl+9ra9Liq6oWv19GR2s3MrH/lJIUnJf0PSYuz22XAU8M453LgLElP\nAz8CXi/phwMdUFUFmzaloaGjj07Job4+1WNubYWtW9PQ0Y4daYhp/vzUq2hvT/MR7e3pNnfuMKI2\nM5sAFBED7yDNBL4MnJI13QF8OSK2Dvvk0qnApwe7+mjOnMZ44xubfPWRmdkQSFodEY1DOaacBfG2\nkkpwFmbxYli1aujHLVx4wEMxMxvXylk6u2Ky+Ynbi4zBzMx6eEE8MzPLDZgUJFVJ+uRIBWNmZsVy\njWYzM8u5RrOZmeVco9nMzHKu0WxmZrlBk4KkWuCvgMWl+0fEV/o7xszMxqZyho9uBJ4HVgPtlQ3H\nzMyKVE5SODwizqh4JGZmVrhyfrz2W0kvq3gkZmZWuHJ6CqcA75P0FGn4SKQKbMdWNDIzMxtx5SSF\nv6h4FGZmNiqUc0lq80gEYmZmxSt0ldRyPfBAqpFw4onpft06eP75VJv5iCNg+vRUbvPQQ2Hp0lRv\nYerUVLpz2zbYsiXVXqithcMOS6/h2gpmZvsatMjOaFBT0xjTpzexY0eqsDZ9OixalArsdHTAscem\n5BCR2k84IVVjmzcvFdrZuDEV4Zk3L5XynDMnJQ8nBjMbz/anyM6YWDp70qRUXjMi/eU/fXoqzVlb\nm25r16aynHPmpB7EI4+knsL69any2owZaXv37nS/a1dKFmZm9kJjIilI6S98SPdVVenLPgImT04J\nYc+eVHazszMljvr6VLO5szPtM3ly6lVMnpza2tqKfU9mZqPRmJhTiEiJANJ9Z2dKAFL6oq+vT1/2\nbW3p+RkzUq9g2jTo6koJA9K8w549aZ+6uuLej5nZaDUmegpdXWnIR0pf+M8/D7Nnp8nj9vaeieNN\nm9LQ0ktfmiaZ589PX/7btqXt+vp039AAc+cW/a7MzEafMdNTqKuDk09+4dVHRx7Z/9VHS5emBFBd\nneYd2ttTUlm40FcfmZn1Z0wkheOOg6amoR83a1ZKAmZmVp4xMXxkZmYjw0nBzMxyTgpmZpZzUjAz\ns5yTgpmZ5ZwUzMws56RgZmY5JwUzM8s5KZiZWc5JwczMck4KZmaWc1IwM7Ock4KZmeVGfJVUSQuA\nq4F5QBewMiKuHOiY1avTstfp+LSUtpTqIkyfnlZDnTIlLa89fTq86lVwzjnw4henkpx33w1btqSi\nO4sXp5oMdXWppoKX0DYz66GIGNkTSocCh0bEvZKmAauBv4yIR/o/pjGg/7Wz6+tTNbbZs9My211d\ncNRR8M53wsMPpyRQUwNPPZUqsp1xRk+RnkWLnBjMbHyStDoiGodyzIgPH0XEsxFxb/Z4B/AoMH84\nr7l7d0oMXV2weTMcfDA89xxce21KCDNmpHrNs2alZPDAA6nwTm0ttLQciHdlZjY+FDqnIGkxcAJw\nVx/PXSipSVJTGmUa7LXSsFJ3gtizBzZsSENGkLYnT4apU1N5Tki9h7a2A/Z2zMzGvMKSgqSpwE+A\nT0TE9t7PR8TKiGhMXZ/Bw+yeZ6ivT4lh8uRUlnPHjvT85MkpMezcmXoOAB0daW7BzMySQpKCpMmk\nhHBtRFw/3NfrTgSTJqXhoY0b4ZBD4LzzUq9g27bUY9iyJQ0vHXdcmk9ob0+TzWZmlhRx9ZGA7wCP\nRsTXh378wFcfVVe/8OqjJUt6rj46/PB09dFBB0FVlSeZzcx6K+Lqo1OAXwMP0jNZ8PmIuLm/Yxob\nG6Opqf+rj8zMbF/7c/XRiPcUIuJOQCN9XjMzG5x/0WxmZjknBTMzyzkpmJlZzknBzMxyTgpmZpZz\nUjAzs5yTgpmZ5ZwUzMws56RgZmY5JwUzM8s5KZiZWc5JwczMck4KZmaWG/FVUvfH6tWpfsJQTJkC\nL395Krjzpz/1tC9ZAkcfnWoxLF8OjY2wdGmqydCXq6+GFStg0yaYMwcuugje8579fy9mZqPZmEgK\n+6O1Fe68c9/2p55Kzx1zDNx0E9TWwtatcNJJ+yaGq6+Gyy5LRXnmz0/7XXZZes6JwczGowk5fLRh\nQyrXWVcHv/kNTJ0Kjz22734rVqSEMG9eSh7z5qXtFStGPmYzs5EwIZMCpHKcdXVpWKi+HrZv33ef\nTZtg5swXts2cmdrNzMajCZsUOjuhrS3NE+zenXoAvc2Zk4aMSm3dmtrNzMajCZkU5s2D555LSWH5\ncti5M00293bRRakHsWEDtLen++3bU7uZ2Xg0bieay7366GUv6//qo+7J5BUrYP361EO49FJPMpvZ\n+KWIKDqGQTU2NkZTU1PRYZiZjSmSVkdE41COmZDDR2Zm1jcnBTMzyzkpmJlZzknBzMxyTgpmZpZz\nUjAzs5yTgpmZ5ZwUzMws56RgZmY5JwUzM8s5KZiZWc5JwczMck4KZmaWc1IwM7NcIUlB0hmSHpP0\nhKTPDrZ/R0eqibBmDbS2Du1cra3puP093sxsIhnxpCCpCvgn4C+AlwLnSnrpQMdEpKI4nZ3Q3Fz+\nF3tra9q/s3P/jjczm2iK6Cm8EngiIp6MiA7gR8DZAx0waRJIUFubbi0t5Z2opaXnmP053sxsoimi\nHOd8YG3J9jrgVb13knQhcGG21TF/fu0fe56tmgSt7YOfakotdHbt217u8aPSHGBT0UGMEv4seviz\n6OHPokcf1ecHVkRSUB9t+9QEjYiVwEoASU0R7UMqKTdepc9iaOX1xit/Fj38WfTwZ9FD0pDrGBcx\nfLQOWFCyfTjwTAFxmJlZL0UkhXuAIyUtkVQDvAu4qYA4zMyslxEfPoqIvZIuAm4BqoDvRsTDgxy2\nsvKRjRn+LHr4s+jhz6KHP4seQ/4sFLHPcL6ZmU1Q/kWzmZnlnBTMzCw3qpPCUJfDGK8kLZB0m6RH\nJT0s6eKiYyqapCpJ90n6adGxFEnSDEnXSfpj9v/Hq4uOqSiSPpn9+3hI0ipJdUXHNFIkfVfSRkkP\nlbTNkvQLSY9n9zPLea1RmxT2ZzmMcWwv8KmIeAlwEvDRCfxZdLsYeLToIEaBK4H/jIhlwHFM0M9E\n0nzg40BjRBxDuojlXcVGNaK+D5zRq+2zwK0RcSRwa7Y9qFGbFNiP5TDGq4h4NiLuzR7vIP3Dn19s\nVMWRdDjwZuCqomMpkqSDgNcC3wGIiI6I2FZsVIWqBqZIqgbqmUC/f4qIO4AtvZrPBn6QPf4B8Jfl\nvNZoTgp9LYcxYb8Iu0laDJwA3FVsJIX6BnAp0McSJhPKi4AW4HvZUNpVkhqKDqoIEbEe+BqwBngW\neD4ifl5sVIU7JCKehfSHJXBwOQeN5qRQ1nIYE4mkqcBPgE9ExPai4ymCpDOBjRGxuuhYRoFq4ETg\nWxFxArCLMocIxptsvPxsYAlwGNAg6d3FRjU2jeak4OUwSkiaTEoI10bE9UXHU6DlwFmSniYNKb5e\n0g+LDakw64B1EdHda7yOlCQmojcAT0VES0TsAa4HTi44pqI9J+lQgOx+YzkHjeak4OUwMpJEGjd+\nNCK+XnQ8RYqIz0XE4RGxmPT/xC8jYkL+RRgRG4C1krpXwjwNeKTAkIq0BjhJUn327+U0Juike4mb\ngPdmj98L3FjOQUWsklqW/VwOY7xaDpwPPCjp/qzt8xFxc4Ex2ejwMeDa7A+nJ4H3FxxPISLiLknX\nAfeSrta7jwm03IWkVcCpwBxJ64AvAlcA/ybpA6Sk+Y6yXsvLXJiZWbfRPHxkZmYjzEnBzMxyTgpm\nZpZzUjAzs5yTgpmZ5ZwUbMKQ9Ple278tKpYiSDpe0puKjsNGN1+SahOGpJ0RMbXoOAaT/fhKEXFA\n13aS9D7SKqIXHcjXtfHFPQUbNST9bVY/47+y9fA/nbXfLqkxezwnW+Kiu6bCVyXdI+kPkj6UtR8q\n6Q5J92dr679G0hWkFTTvl3Rttt/O7F7Z6zwk6UFJ52Ttp2bn7q5XcG32hY2kKyQ9kp33a328ly9J\nukbSL7P17D9Y8twlJTF/OWtbnNVD+GfSD7AW9Hq9pyX9g6S7s9uLs/ZFkm7NXutWSQuz9ndk7+eB\n7LOoAb4CnJN9BuccqP9uNr6M2l8028Qi6eWkZStOIP1/eS8w2KJ3HyCthvkKSbXAbyT9HHgbcEtE\n/F1Wl6M+In4t6aKIOL6P13kbcDypHsEc4B5Jd2TPnQAcTVp36zfAckmPAG8FlkVESJrRT3zHkupf\nNAD3SfoZcAxwJGlpeAE3SXot6RenS4H3R8RH+nm97RHxSknvIa0UeyawArg6In4g6QLgm6Qlkr8A\nnB4R6yXNiIgOSV/APQUbhHsKNlq8BrghInZnK8CWs87VnwPvyZb+uAuYTfrCvQd4v6QvAS/LalAM\n5BRgVUR0RsRzwK+AV2TP3R0R67KhnPuBxcB2oA24StLbgN39vO6NEdEaEZuA20iJ4M+z232kxLcs\nixmgOSJ+P0Ccq0ruuyusvRr41+zxNdl7gZTAvp/1UKoGef9mOfcUbDTpb4JrLz1/wJSWWBTwsYi4\npfcB2V/fbwaukfTViLh6gPP2tUx7t/aSx51AdbYu1ytJi669C7gIeH0fx/Z+P5Gd6/KI+Jde8S4m\nLX09kOjn8T77RMSHJb2K9BncL6mvHpLZPtxTsNHiDuCtkqZImga8peS5p4GXZ4/fXtJ+C/Dfs2XF\nkXSUpAZJi0g1F75NWl22eznpPd379nHuc7I5irmkamZ39xeoUl2L6dmChJ8gDT315WxJdZJmkxYr\nuyeL+YLsNZA0X1JZxU+Ac0ruf5c9/i09ZSfPA+7MXveIiLgrIr4AbCLNUewAppV5Lpug3FOwUSEi\n7pX0Y9IQTTPw65Knv0Za7fF84Jcl7VeRhnPuzSaAW0jj6acCl0jaA+wE3pPtvxL4g6R7I+K8kte5\ngTQM8wDpL+1LI2KDpGX9hDsNuFGpMLyAT/az393Az4CFwP+MiGeAZyS9BPhdNme9E3g3qRcymFpJ\nd5H+mDs3a/s48F1Jl2Tvv3uV1K9KOjKL79bsva0BPpsNt10eET8u45w2wfiSVBuVsvmAnRGxz5U9\nY8GBjj+74qoxm58wqxgPH5mZWc49BTMzy7mnYGZmOScFMzPLOSmYmVnOScHMzHJOCmZmlvv/mohF\nRMwYLGkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x6919d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.close()\n",
    "binlist = make_binlist(D,1) #timetick in (whole) days\n",
    "pp = PdfPages(\"plots-author-BVN.pdf\")\n",
    "normaldict = defaultdict(list)\n",
    "nonnormaldict = defaultdict(list)\n",
    "averagedict = defaultdict(list)\n",
    "countnonnormal = defaultdict(list)\n",
    "\n",
    "for user in tqdm(T):\n",
    "    if len(T[user])<30:\n",
    "        pass # go to next user. This one has too little activity\n",
    "    else:\n",
    "        first_date = 0\n",
    "        last_date = 0\n",
    "        print \"User: \", user, \"- Active bins: \", len(T[user])   \n",
    "        # variables\n",
    "        bindict = defaultdict(list)\n",
    "        postdict = defaultdict(list)\n",
    "        sendict = defaultdict(list)\n",
    "        questdict = defaultdict(list)\n",
    "        objecdict = defaultdict(list)\n",
    "        lengthdict = defaultdict(list)\n",
    "        senlengthdict = defaultdict(list)\n",
    "        startsdict = defaultdict(list)\n",
    "        responsesdict = defaultdict(list)\n",
    "        # length of posts (in words, or sentences)\n",
    "        # nr of replies to posts vs nr of starting posts\n",
    "        # linguistic markers, like adjectives / pronouns / emoticons, and the diversity of topics / vocabulary\n",
    "\n",
    "        # variables (plottable)\n",
    "        nr_of_posts = dict()\n",
    "        mean_quest = dict()\n",
    "        mean_sent = dict()\n",
    "        mean_object = dict()\n",
    "        mean_length = dict()\n",
    "        mean_sents_length = dict()\n",
    "        nr_of_starts = dict()\n",
    "        nr_of_responses = dict()\n",
    "\n",
    "        for index,boundary in enumerate(binlist):\n",
    "            if index+1>=len(binlist):\n",
    "                break\n",
    "            else:\n",
    "                lower = binlist[index]\n",
    "                upper = binlist[index+1]\n",
    "\n",
    "                for time in T[user]:\n",
    "                    if lower<=datetime.strptime(time, '%d/%m/%Y - %H:%M')<upper:\n",
    "                        if first_date == 0:\n",
    "                            first_date = datetime.strptime(time, '%d/%m/%Y - %H:%M')\n",
    "                            last_date = datetime.strptime(time, '%d/%m/%Y - %H:%M')\n",
    "                        else:\n",
    "                            last_date = datetime.strptime(time, '%d/%m/%Y - %H:%M')\n",
    "                        \n",
    "                        first_week = first_date + timedelta(days = 7)\n",
    "                        if datetime.strptime(time, '%d/%m/%Y - %H:%M')>first_week:\n",
    "                            \n",
    "                        \n",
    "                        body = P[user][T[user].index(time)][0]\n",
    "                        meta = P[user][T[user].index(time)][1]\n",
    "\n",
    "                        senti = determine_sentiment(body) # average sentiment per sentence in body\n",
    "                        questionmarks = determine_questionmarks(body) # ratio of sentences in body ending with question marks\n",
    "                        objectivity = determine_objectivity(body)\n",
    "                        length = determine_length(body)\n",
    "                        sentence_length = determine_sent_length(body)\n",
    "                        if meta == 0: # 0 is for the response to a thread, 1 is the start of thread\n",
    "                            response = 1\n",
    "                            start = 0\n",
    "                        elif meta == 1:\n",
    "                            response = 0\n",
    "                            start = 1\n",
    "\n",
    "                        bindict[lower,upper].append(time)\n",
    "                        postdict[lower,upper].append(body) \n",
    "                        sendict[lower,upper].append(senti)\n",
    "                        questdict[lower,upper].append(questionmarks)\n",
    "                        objecdict[lower,upper].append(objectivity)\n",
    "                        lengthdict[lower,upper].append(length)\n",
    "                        senlengthdict[lower,upper].append(sentence_length)\n",
    "                        startsdict[lower,upper].append(start)\n",
    "                        responsesdict[lower,upper].append(response)\n",
    "\n",
    "            # fill up empty places in dictionary\n",
    "            if len(bindict[lower,upper])==0:\n",
    "                bindict[lower,upper]=[]\n",
    "                postdict[lower,upper]=[]\n",
    "                sendict[lower,upper]=[]\n",
    "                questdict[lower,upper]=[]\n",
    "                objecdict[lower,upper]=[]\n",
    "                lengthdict[lower,upper]=[]\n",
    "                senlengthdict[lower,upper]=[]\n",
    "                startsdict[lower,upper]=[]\n",
    "                responsesdict[lower,upper]=[]\n",
    "\n",
    "        #convert dictionaries to things you want plotted, like averages:\n",
    "        for lower,upper in bindict: \n",
    "            # mean nr of sentences per timetick\n",
    "            if len(bindict[lower,upper])==0:\n",
    "                nr_of_posts[lower,upper]=float('nan')\n",
    "                mean_quest[lower,upper]=float('nan')\n",
    "                mean_sent[lower,upper]=float('nan')\n",
    "                mean_object[lower,upper]=float('nan')\n",
    "                mean_length[lower,upper]=float('nan')\n",
    "                mean_sents_length[lower,upper]=float('nan')\n",
    "                nr_of_starts[lower,upper]=float('nan')\n",
    "                nr_of_responses[lower,upper]=float('nan')\n",
    "            else:\n",
    "                with warnings.catch_warnings():\n",
    "                    warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "                    nr_of_posts[lower,upper]=len(bindict[lower,upper])\n",
    "                    mean_quest[lower,upper]=np.mean(questdict[lower,upper])\n",
    "                    mean_sent[lower,upper]=np.mean(sendict[lower,upper])\n",
    "                    mean_object[lower,upper]=np.mean(objecdict[lower,upper])\n",
    "                    mean_length[lower,upper]=np.mean(lengthdict[lower,upper])\n",
    "                    mean_sents_length[lower,upper]=np.mean(senlengthdict[lower,upper])\n",
    "                    nr_of_starts[lower,upper]=np.nansum(startsdict[lower,upper])\n",
    "                    nr_of_responses[lower,upper]=np.nansum(responsesdict[lower,upper])\n",
    "\n",
    "        # we have collected all data for a single user, and now we do stuff with it:\n",
    "        active_time = last_date-first_date\n",
    "        print \"last: \", last_date, \" - first:\", first_date, \" = activity spread:\", active_time\n",
    "        # maak plotje van alle variabelen\n",
    "        #compare_variables(pp,user,nr_of_posts,mean_quest,mean_object,mean_sent,mean_length,mean_sents_length,nr_of_starts,nr_of_responses)\n",
    "        compare_two(user,mean_quest,nr_of_responses)\n",
    "        \n",
    "        # maak dataframe van alle variabelen\n",
    "        df = pd.DataFrame({'Que': mean_quest.values(), 'Sub': mean_object.values(), 'Sen': mean_sent.values(),'Len': mean_length.values(), 'Wor': mean_sents_length.values(),'Sta': nr_of_starts.values(),'Res': nr_of_responses.values()}).dropna()\n",
    "\n",
    "        #plot de boel:\n",
    "        #plt.close()\n",
    "        # bepaal correlatiematrix van variabelen\n",
    "        for m in ['pearson', 'kendall']:\n",
    "            rho = df.corr(method = m) #dubbel..\n",
    "            #visualise(df, m)\n",
    "        #plt.show()\n",
    "plt.show()        \n",
    "# show average correlations (per test, and in general)\n",
    "#show_correlations([averagedict,normaldict,nonnormaldict],countnonnormal, rho)\n",
    "\n",
    "pp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014-11-08 09:36:00  \\  2014-11-08 09:36:00  /  2014-11-15 09:36:00\n",
      "2014-11-15 09:36:00  \\  2014-11-17 09:36:00  /  2014-11-22 09:36:00\n",
      "2014-12-13 09:36:00  \\  2014-12-18 09:36:00  /  2014-12-20 09:36:00\n",
      "2014-12-20 09:36:00  \\  2014-12-26 09:36:00  /  2014-12-27 09:36:00\n"
     ]
    }
   ],
   "source": [
    "#determine nr of posts in a week\n",
    "\n",
    "first_date = datetime.strptime(\"25/10/2014 - 09:36\", '%d/%m/%Y - %H:%M')\n",
    "last_date = first_date + timedelta(days=366)\n",
    "dates = [first_date + timedelta(days=62),first_date + timedelta(days=23),first_date + timedelta(days=14),first_date + timedelta(days=54)]\n",
    "\n",
    "for d in range(0,(last_date-first_date).days,7):\n",
    "    border1 = first_date+timedelta(days=d)\n",
    "    border2 = first_date+timedelta(days=d+7)\n",
    "    for a_date in dates:\n",
    "        if border1<=a_date<border2:\n",
    "            print border1, \" \\ \", a_date, \" / \", border2\n",
    "            # write to dictionary with borders as keys (start dict at first activity, end at last)\n",
    "\n",
    "# determine average length of values in dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 4) -0.0371477826962\n",
      "(5, 4) -0.0116371475249\n",
      "(5, 0) 0.167089688543\n",
      "(3, 0) 0.0351211230674\n",
      "(5, 2) 0.0491713185558\n",
      "(6, 1) -0.0329269224226\n",
      "(3, 1) 0.0569689490541\n",
      "(3, 2) 0.167349250464\n",
      "(2, 1) 0.247009057214\n",
      "(6, 0) 0.110506895394\n",
      "(6, 3) 0.0591017614612\n",
      "(2, 0) 0.116947043632\n",
      "(6, 2) 0.0647423888313\n",
      "(4, 3) 0.0330315516744\n",
      "(5, 1) 0.0062988958561\n",
      "(4, 2) 0.0566331265763\n",
      "(1, 0) 0.0776204892785\n",
      "(5, 3) 0.18647860511\n",
      "(4, 1) 0.151254831936\n",
      "(6, 5) 0.290548054865\n",
      "(4, 0) 0.0435062984641\n",
      "          Len       Que       Res       Sen       Sta       Sub  Wor\n",
      "Len       NaN       NaN       NaN       NaN       NaN       NaN  NaN\n",
      "Que  0.077620       NaN       NaN       NaN       NaN       NaN  NaN\n",
      "Res  0.116947  0.247009       NaN       NaN       NaN       NaN  NaN\n",
      "Sen  0.035121  0.056969  0.167349       NaN       NaN       NaN  NaN\n",
      "Sta  0.043506  0.151255  0.056633  0.033032       NaN       NaN  NaN\n",
      "Sub  0.167090  0.006299  0.049171  0.186479 -0.011637       NaN  NaN\n",
      "Wor  0.110507 -0.032927  0.064742  0.059102 -0.037148  0.290548  NaN\n"
     ]
    }
   ],
   "source": [
    "frame = pd.DataFrame().reindex_like(rho)\n",
    "for (i,j) in averagedict:\n",
    "    print (i,j), np.nanmean(averagedict[(i,j)])\n",
    "    frame.iloc[i][j]=np.nanmean(averagedict[(i,j)])\n",
    "print frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A  B\n",
       "1  2  2\n",
       "4  3  5\n",
       "3  4  4\n",
       "0  6  1\n",
       "2  7  3"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\"A\": [6,2,7,4,3], \"B\":[1,2,3,4,5]})\n",
    "df.sort_values(\"A\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
